# -*- coding: utf-8 -*-
"""walkingbass.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-uGYdaYGjniYDvdTN2_bt7nfRw_X6ymv
"""

#from google.colab import drive
#drive.mount('/content/drive')

import numpy as np
import tensorflow as tf
from random import random
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.utils import np_utils
from IPython.display import Audio
from IPython.core.display import display
from time import sleep
from keras import callbacks

dataset = np.loadtxt('/content/drive/MyDrive/Colab Notebooks/Classroom/data/walkingbass_data.txt', delimiter=',') # ide jon a walkingbass_data.txt

labelsmoothing = 0 # nem hasznalom, mert elrontja a kimenetet

#	Float in [0, 1]. When 0, no smoothing occurs. When > 0, we compute the loss between the predicted 
# labels and a smoothed version of the true labels, where the smoothing squeezes the labels towards 0.5. 
# Larger values of label_smoothing correspond to heavier smoothing.
# https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy

# model validalas, erre a rejtett retegek neuronjainak szamainak es az epochok szamainak meghatarozasara volt szukseg
#which_model = 2

#train_X = dataset[0:100,0:which_model]
#train_y = dataset[0:100,which_model]
#train_dummy_y = np_utils.to_categorical(train_y)
#test_X = dataset[101:145,0:which_model]
#test_y = dataset[101:145,which_model]
#test_dummy_y = np_utils.to_categorical(test_y)
#earlystopping = callbacks.EarlyStopping(monitor ="val_loss", 
#                                        mode ="min", patience = 5, 
#                                        restore_best_weights = True)
  
#history = model_2.fit(train_X, train_dummy_y, batch_size = 16, # itt kezzel kell atirni
#                    epochs = 100, validation_data =(test_X, test_dummy_y), 
#                    callbacks =[earlystopping])

# model_1; dorian masodik negyed

X_1 = dataset[:,0] # fuggo valtozo
y_1 = dataset[:,1] # fuggetlen valtozo
dummy_y_1 = np_utils.to_categorical(y_1) # one-hot kodolt fuggetlen valtozo

model_1 = Sequential()
model_1.add(Dense(20, input_dim=1, activation='relu'))
model_1.add(Dense(20, activation='relu'))
model_1.add(Dense(23, activation='softmax'))

opt = keras.optimizers.Adam(learning_rate=0.001) # gradient descent optimization, ezt a setupot hasznalja az osszes modell
model_1.compile(loss=tf.keras.losses.CategoricalCrossentropy(
    from_logits=False, label_smoothing=labelsmoothing, axis=-1,
    name='categorical_crossentropy'), optimizer=opt,metrics =['accuracy']) # logarithmic loss function

model_1.fit(X_1, dummy_y_1, epochs=18, batch_size=16,verbose=0)

# model_2; dorian harmadik negyed

X_2 = dataset[:,0:2]
y_2 = dataset[:,2]
dummy_y_2 = np_utils.to_categorical(y_2)

model_2 = Sequential()
model_2.add(Dense(12, input_dim=2, activation='relu'))
model_2.add(Dense(16, activation='relu'))
model_2.add(Dense(26, activation='softmax'))

model_2.compile(loss=tf.keras.losses.CategoricalCrossentropy(
    from_logits=False, label_smoothing=labelsmoothing, axis=-1,
    name='categorical_crossentropy'), optimizer=opt,metrics =['accuracy'])

model_2.fit(X_2, dummy_y_2, epochs=32, batch_size=16,verbose=0)

# model_3; dorian negyedik negyed, leading tone

X_3 = dataset[:,0:3]
y_3 = dataset[:,3]
dummy_y_3 = np_utils.to_categorical(y_3)

model_3 = Sequential()
model_3.add(Dense(10, input_dim=3, activation='relu'))
model_3.add(Dense(20, activation='relu'))
model_3.add(Dense(23, activation='softmax'))

model_3.compile(loss=tf.keras.losses.CategoricalCrossentropy(
    from_logits=False, label_smoothing=labelsmoothing, axis=-1,
    name='categorical_crossentropy'), optimizer=opt,metrics =['accuracy'])

model_3.fit(X_3, dummy_y_3, epochs=28, batch_size=16,verbose=0)

# model_4; mixolydian elso negyed, alaphang

X_4 = dataset[:,0:4]
y_4 = dataset[:,4]
dummy_y_4 = np_utils.to_categorical(y_4)

model_4 = Sequential()
model_4.add(Dense(12, input_dim=4, activation='relu'))
model_4.add(Dense(18, activation='relu'))
model_4.add(Dense(21, activation='softmax'))

model_4.compile(loss=tf.keras.losses.CategoricalCrossentropy(
    from_logits=False, label_smoothing=labelsmoothing, axis=-1,
    name='categorical_crossentropy'), optimizer=opt,metrics =['accuracy'])

model_4.fit(X_4, dummy_y_4, epochs=20, batch_size=16,verbose=0)

# model_5; mixolydian masodik negyed

X_5 = dataset[:,0:5]
y_5 = dataset[:,5]
dummy_y_5 = np_utils.to_categorical(y_5)

model_5 = Sequential()
model_5.add(Dense(15, input_dim=5, activation='relu'))
model_5.add(Dense(30, activation='relu'))
model_5.add(Dense(28, activation='softmax'))

model_5.compile(loss=tf.keras.losses.CategoricalCrossentropy(
    from_logits=False, label_smoothing=labelsmoothing, axis=-1,
    name='categorical_crossentropy'), optimizer=opt,metrics =['accuracy'])

model_5.fit(X_5, dummy_y_5, epochs=12, batch_size=16,verbose=0)

# model_6; mixolydian harmadik negyed

X_6 = dataset[:,0:6]
y_6 = dataset[:,6]
dummy_y_6 = np_utils.to_categorical(y_6)

model_6 = Sequential()
model_6.add(Dense(16, input_dim=6, activation='relu'))
model_6.add(Dense(28, activation='relu'))
model_6.add(Dense(31, activation='softmax'))

model_6.compile(loss=tf.keras.losses.CategoricalCrossentropy(
    from_logits=False, label_smoothing=labelsmoothing, axis=-1,
    name='categorical_crossentropy'), optimizer=opt,metrics =['accuracy'])

model_6.fit(X_6, dummy_y_6, epochs=18, batch_size=16,verbose=0)

# model_7; mixolydian negyedik negyed, leading tone

X_7 = dataset[:,0:7]
y_7 = dataset[:,7]
dummy_y_7 = np_utils.to_categorical(y_7)

model_7 = Sequential()
model_7.add(Dense(16, input_dim=7, activation='relu'))
model_7.add(Dense(26, activation='relu'))
model_7.add(Dense(28, activation='softmax'))

model_7.compile(loss=tf.keras.losses.CategoricalCrossentropy(
    from_logits=False, label_smoothing=labelsmoothing, axis=-1,
    name='categorical_crossentropy'), optimizer=opt,metrics =['accuracy'])

model_7.fit(X_7, dummy_y_7, epochs=12, batch_size=16,verbose=0)

# model_8; ionian elso negyed, alaphang

X_8 = dataset[:,0:8]
y_8 = dataset[:,8]
dummy_y_8 = np_utils.to_categorical(y_8)

model_8 = Sequential()
model_8.add(Dense(10, input_dim=8, activation='relu'))
model_8.add(Dense(20, activation='relu'))
model_8.add(Dense(26, activation='softmax'))

model_8.compile(loss=tf.keras.losses.CategoricalCrossentropy(
    from_logits=False, label_smoothing=labelsmoothing, axis=-1,
    name='categorical_crossentropy'), optimizer=opt,metrics =['accuracy'])

model_8.fit(X_8, dummy_y_8, epochs=22, batch_size=16,verbose=0)

# model_9; ionian masodik negyed

X_9 = dataset[:,0:9]
y_9 = dataset[:,9]
dummy_y_9 = np_utils.to_categorical(y_9)

model_9 = Sequential()
model_9.add(Dense(15, input_dim=9, activation='relu'))
model_9.add(Dense(25, activation='relu'))
model_9.add(Dense(33, activation='softmax'))

model_9.compile(loss=tf.keras.losses.CategoricalCrossentropy(
    from_logits=False, label_smoothing=labelsmoothing, axis=-1,
    name='categorical_crossentropy'), optimizer=opt,metrics =['accuracy'])

model_9.fit(X_9, dummy_y_9, epochs=14, batch_size=16,verbose=0)

# model_10; ionian harmadik negyed

X_10 = dataset[:,0:10]
y_10 = dataset[:,10]
dummy_y_10 = np_utils.to_categorical(y_10)

model_10 = Sequential()
model_10.add(Dense(16, input_dim=10, activation='relu'))
model_10.add(Dense(28, activation='relu'))
model_10.add(Dense(37, activation='softmax'))

model_10.compile(loss=tf.keras.losses.CategoricalCrossentropy(
    from_logits=False, label_smoothing=labelsmoothing, axis=-1,
    name='categorical_crossentropy'), optimizer=opt,metrics =['accuracy'])

model_10.fit(X_10, dummy_y_10, epochs=22, batch_size=16,verbose=0)

# model_11; ionian negyedik negyed, leading tone

X_11 = dataset[:,0:11]
y_11 = dataset[:,11]
dummy_y_11 = np_utils.to_categorical(y_11)

model_11 = Sequential()
model_11.add(Dense(24, input_dim=11, activation='relu'))
model_11.add(Dense(28, activation='relu'))
model_11.add(Dense(33, activation='softmax'))

model_11.compile(loss=tf.keras.losses.CategoricalCrossentropy(
    from_logits=False, label_smoothing=labelsmoothing, axis=-1,
    name='categorical_crossentropy'), optimizer=opt,metrics =['accuracy'])

model_11.fit(X_11, dummy_y_11, epochs=18, batch_size=16,verbose=0)

# fitness proportionate selection, ez kivalaszt egy kategoriat a multisoft kimenetbol
def randomselect(x):
    prob_range = x.cumsum()
    prob_range = np.insert(prob_range, 0, 0)
    ran_num = random()
    for i in range(0,len(x)):
        if prob_range[i] <= ran_num <= prob_range[i+1]:
            return i

# ez feedeli az egymast koveto modelleket, kimenete egy 12 elemu vektor, amelynek elemei megfelelnek zenei intervallumnak
def predictline():
  v = [0] * 12
  v[0] = 15
  prediction = model_1.predict(np.array(v[0],ndmin=2))
  v[1] = randomselect(prediction[0])
  models = (model_1,model_2,model_3,model_4,model_5,model_6,model_7,model_8,model_9,model_10,model_11)
  for i in range(1,11):
    prediction = models[i].predict(np.array(v[0:i+1],ndmin=2))
    v[i+1] = randomselect(prediction[0])
  return v

# ez lejatszik egy hangot
def playnote(note):
  notelist = list(range(1,37)) # az egyes szamok egy hangnak felelnek meg pl.: 1 = E; 2 = F; 3 = F sharp/G flat
  for i in notelist:
    if note == i:
      display(Audio('/content/drive/MyDrive/Colab Notebooks/Classroom/bass_sounds/' + str(i) + '.wav', autoplay = True)) # ide jon a bass_sounds mappa

# ez annak fuggvenyeben h milyen alaphangot valasztunk, modifikalja a bassline-t
def whichkey(line,key):
  keylist = ('E','F','Fs','G','Gs','A','As','B','C','Cs','D','Ds')
  for i in range(0,len(keylist)):
    if key == keylist[i]:
      new_line = [j+i for j in line]
      return new_line

# ez lejatsza a predictline() kimenetet
def playline(line,key):
  line = whichkey(line,key)
  line = np.array(line)-6 # erre azert van szukseg mert sajnos nem minden bassline kivitelezheto minden hangnemben
  for i in line:          # ha E alaphangbol kivonok 6-ot abbol As/Bb alaphang lesz, ez akad be a legkevesebbszer
    playnote(i)
    n=1
    sleep(n) # szunet a hangok kozott, ha minden jol mukodne, akkor pontosan n mp-kent lejatszana egy hangot

bassline = predictline()
print(bassline)
playline(bassline,'E') # E, F, Fs, G, Gs, A, As, B, C, Cs,D, Ds

# sajnos ugy tunik h browser based editor nem szeret minden audio objectet kezelo python toolboxot, ami mukodik pedig
# nem igazan alkalmas arra, amire en hasznalnam. ebbol kifolyolag a temporalis precizio nem az igazi (kifejezetten rossz).
# ha kiemelnem a jupyter kornyezetebol, akkor pl hasznalhatnek simpleaudio modult, ami valoszinuleg jobban mukodne,
# erre viszont sajnos nem volt idom